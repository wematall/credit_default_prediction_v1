{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Курсовой проект"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "построение модели\n",
    "для прогнозирования невыполнения долговых обязательств по текущему кредиту"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Содержание проекта:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Построение модели классификации**<br>\n",
    "[1. Обзор обучающего датасета](#1)<br>\n",
    "[2. Обработка выбросов](#2)<br>\n",
    "[3. Обработка пропусков](#3)<br>\n",
    "[4. Анализ данных](#4)<br>\n",
    "[5. Отбор признаков](#5)<br>\n",
    "[6. Балансировка классов](#6)<br>\n",
    "[7. Подбор моделей, получение бейзлана](#7)<br>\n",
    "[8. Выбор наилучшей модели, настройка гиперпараметров](#8)<br>\n",
    "[9. Проверка качества, борьба с переобучением](#9)<br>\n",
    "[10. Интерпретация результатов](#10)<br>\n",
    "\n",
    "**Прогнозирование на тестовом датасете**<br>\n",
    "[11. Выполнить для тестового датасета те же этапы обработки и постронияния признаков](#11)<br>\n",
    "[12. Спрогнозировать целевую переменную, используя модель, построенную на обучающем датасете](#12)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Практическая часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пути к директориям и файлам\n",
    "TRAIN_DATASET_PATH = 'data/course_project_train.csv'\n",
    "TEST_DATASET_PATH = 'data/course_project_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-765d80536298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcatb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# импорт необходимых библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score, learning_curve\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import catboost as catb\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Построение модели классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom methods\n",
    "\n",
    "# функция для просмотра номинативных признаков\n",
    "def catnames_overview(data):\n",
    "    for cat_colname in data.select_dtypes(include='object').columns:\n",
    "        print(str(cat_colname) + '\\n\\n' + str(data[cat_colname].value_counts()) + '\\n' + '*' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# метод для заполнения пропусков\n",
    "\n",
    "def imputer_rfr(data, target_col):\n",
    "    data = data.copy()\n",
    "    \n",
    "    features = data.columns\n",
    "    \n",
    "    data = data[features]\n",
    "    \n",
    "    train = data[~data[target_col].isna()]\n",
    "    predict_data = data[data[target_col].isna()]\n",
    "\n",
    "    X = train.drop(columns=target_col)\n",
    "    y = train[target_col]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        shuffle=True,\n",
    "                                                        random_state=32)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100,\n",
    "                                  max_depth=10,\n",
    "                                  random_state=42,\n",
    "                                  verbose=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    print(f\"r2 на train: {r2_score(y_train, pred_train)}\")\n",
    "    print(f\"r2 на test: {r2_score(y_test, pred_test)}\")\n",
    "\n",
    "    pred = model.predict(predict_data.drop(columns=target_col))\n",
    "\n",
    "    data.loc[data[target_col].isna(), target_col] = list(pred)\n",
    "    return model, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Обзор обучающего датасета <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание датасета**\n",
    "\n",
    "* **Home Ownership** - домовладение\n",
    "* **Annual Income** - годовой доход\n",
    "* **Years in current job** - количество лет на текущем месте работы\n",
    "* **Tax Liens** - налоговые обременения\n",
    "* **Number of Open Accounts** - количество открытых счетов\n",
    "* **Years of Credit History** - количество лет кредитной истории\n",
    "* **Maximum Open Credit** - наибольший открытый кредит\n",
    "* **Number of Credit Problems** - количество проблем с кредитом\n",
    "* **Months since last delinquent** - количество месяцев с последней просрочки платежа\n",
    "* **Bankruptcies** - банкротства\n",
    "* **Purpose** - цель кредита\n",
    "* **Term** - срок кредита\n",
    "* **Current Loan Amount** - текущая сумма кредита\n",
    "* **Current Credit Balance** - текущий кредитный баланс\n",
    "* **Monthly Debt** - ежемесячный долг\n",
    "* **Credit Default** - факт невыполнения кредитных обязательств (0 - погашен вовремя, 1 - просрочка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим данные\n",
    "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# посмотрим какие данные есть в колонках\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# размерность нашего набора данных\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим есть ли пропуски\n",
    "# и какие типы данных представлены\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# из списка видим, что есть пропуски\n",
    "# и поэтому понадобиться их заполнить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обзор целевой переменной\n",
    "df_train['Credit Default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обзор количественных (вещественных) признаков\n",
    "# сравним, если mean > 50% \n",
    "# это указывает на наличие выбросов в большую сторону\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Обзор категориальных (номинативных) признаков\n",
    "catnames_overview(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассмотрим где есть пропущенные данные\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделение признакового описания и целевой переменной\n",
    "\n",
    "TARGET_NAME = 'Credit Default'\n",
    "\n",
    "BASE_FEATURE_NAMES = ['Home Ownership', 'Annual Income', 'Years in current job',\n",
    "                     'Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n",
    "                     'Maximum Open Credit', 'Number of Credit Problems', \n",
    "                     'Months since last delinquent',\n",
    "                     'Bankruptcies', 'Purpose', 'Term', 'Current Loan Amount',\n",
    "                     'Current Credit Balance', 'Monthly Debt', 'Credit Score']\n",
    "\n",
    "CAT_FEATURE_NAMES = ['Home Ownership', 'Years in current job', 'Purpose', 'Term']\n",
    "\n",
    "NUM_FEATURE_NAMES = ['Annual Income', 'Tax Liens', \n",
    "                     'Number of Open Accounts', 'Years of Credit History',\n",
    "                     'Maximum Open Credit', 'Number of Credit Problems', \n",
    "                     'Months since last delinquent',\n",
    "                     'Bankruptcies', 'Current Loan Amount',\n",
    "                     'Current Credit Balance', 'Monthly Debt', 'Credit Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Обработка выбросов <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[NUM_FEATURE_NAMES].hist(figsize=(16,16), bins=20, grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Обработка пропусков <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'Annual Income'\n",
    "annual_income_predictor, df_train_copy = imputer_rfr(df_train_copy, feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Анализ данных <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Отбор признаков <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Балансировка классов <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Подбор моделей, получение бейзлана <a class=\"anchor\" id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Выбор наилучшей модели, настройка гиперпараметров <a class=\"anchor\" id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Проверка качества, борьба с переобучением <a class=\"anchor\" id=\"9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Интерпретация результатов <a class=\"anchor\" id=\"10\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Прогнозирование на тестовом датасете"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Выполнить для тестового датасета те же этапы обработки и построения признаков <a class=\"anchor\" id=\"11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим какие данные есть в колонках\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# размерность нашего набора данных\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим есть ли пропуски\n",
    "# и какие типы данных представлены\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# из списка видим, что есть пропуски\n",
    "# и поэтому понадобиться их заполнить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обзор количественных (вещественных) признаков\n",
    "# сравним, если mean > 50% \n",
    "# это указывает на наличие выбросов в большую сторону\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Спрогнозировать целевую переменную, используя модель, построенную на обучающем датасете <a class=\"anchor\" id=\"12\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
